{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 1: Building the Brain\n",
                "\n",
                "## From Scratch to Framework\n",
                "\n",
                "In this lab, you will:\n",
                "\n",
                "1. **Part 1:** Build a \"raw\" ReAct agent from scratch using a simple `while` loop and text parsing\n",
                "2. **Part 2:** Compare your raw agent with the project's `ReactAgent` that uses native function calling\n",
                "\n",
                "### Learning Goals\n",
                "- Understand that an agent is just a **loop** with state and reasoning\n",
                "- Experience the **pain** of parsing free-text tool calls\n",
                "- Appreciate why **native function calling** is used in production\n",
                "\n",
                "### Prerequisites\n",
                "- `uv pip install litellm python-dotenv`\n",
                "- A valid API key in your `.env` file (e.g., `OPENAI_API_KEY=sk-...`)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import json\n",
                "from dotenv import load_dotenv\n",
                "from litellm import completion\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "MODEL = os.getenv(\"MODEL_NAME\", \"gpt-4o\")\n",
                "print(f\"Using model: {MODEL}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 1: The \"Raw\" ReAct Agent\n",
                "\n",
                "We'll build a ReAct agent that uses **text-based** tool calling. The LLM outputs plain text in a specific format, and we parse it to extract tool calls.\n",
                "\n",
                "### Step 1: Define Mock Tools\n",
                "\n",
                "First, let's create some simple tools our agent can use. These are just Python functions — no API keys needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mock tools for our agent\n",
                "\n",
                "def search(query: str) -> str:\n",
                "    \"\"\"Simulate a web search.\"\"\"\n",
                "    mock_results = {\n",
                "        \"capital of france\": \"Paris is the capital and most populous city of France.\",\n",
                "        \"population of paris\": \"The population of Paris is approximately 2.1 million in the city proper and 12.2 million in the metropolitan area.\",\n",
                "        \"eiffel tower height\": \"The Eiffel Tower is 330 metres (1,083 ft) tall, about the same height as an 81-storey building.\",\n",
                "        \"python programming\": \"Python is a high-level, general-purpose programming language created by Guido van Rossum in 1991.\",\n",
                "        \"largest ocean\": \"The Pacific Ocean is the largest and deepest ocean on Earth, covering more than 63 million square miles.\",\n",
                "    }\n",
                "    query_lower = query.lower()\n",
                "    for key, value in mock_results.items():\n",
                "        if key in query_lower or any(word in query_lower for word in key.split()):\n",
                "            return value\n",
                "    return f\"No results found for: {query}\"\n",
                "\n",
                "\n",
                "def calculate(expression: str) -> str:\n",
                "    \"\"\"Evaluate a math expression safely.\"\"\"\n",
                "    try:\n",
                "        allowed = set('0123456789+-*/.(). ')\n",
                "        if all(c in allowed for c in expression):\n",
                "            result = eval(expression)\n",
                "            return str(result)\n",
                "        return \"Error: Invalid expression\"\n",
                "    except Exception as e:\n",
                "        return f\"Error: {e}\"\n",
                "\n",
                "\n",
                "# Tool registry — maps tool names to functions\n",
                "TOOLS = {\n",
                "    \"search\": search,\n",
                "    \"calculate\": calculate,\n",
                "}\n",
                "\n",
                "# Test the tools\n",
                "print(search(\"capital of france\"))\n",
                "print(calculate(\"15 * 500 / 100\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: The ReAct System Prompt\n",
                "\n",
                "We need a system prompt that tells the LLM to follow the Thought -> Action -> Observation format **exactly**. This is the fragile part — the model must follow the format precisely for our parser to work."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "REACT_SYSTEM_PROMPT = \"\"\"You are a helpful research assistant that solves tasks step by step.\n",
                "\n",
                "You have access to these tools:\n",
                "- search(query): Search for information. Input: a search query string.\n",
                "- calculate(expression): Evaluate a math expression. Input: a math expression string.\n",
                "\n",
                "Follow this EXACT format for EVERY step:\n",
                "\n",
                "Thought: <your reasoning about what to do next>\n",
                "Action: <tool_name>(\"<argument>\")\n",
                "\n",
                "After receiving an Observation, continue with the next Thought.\n",
                "\n",
                "When you have enough information to answer, use:\n",
                "\n",
                "Thought: I have enough information to answer.\n",
                "Final Answer: <your complete answer>\n",
                "\n",
                "IMPORTANT:\n",
                "- ALWAYS start with a Thought before any Action.\n",
                "- Use EXACTLY one Action per step.\n",
                "- Wait for the Observation before your next Thought.\n",
                "- Never fabricate Observations — only use real tool results.\n",
                "\"\"\"\n",
                "\n",
                "print(\"System prompt loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Build the Parser\n",
                "\n",
                "This is where the pain begins. We need to parse the LLM's text output to extract:\n",
                "- Whether it produced a **Final Answer** (we're done)\n",
                "- Or an **Action** with a tool name and argument (we need to execute it)\n",
                "\n",
                "**TODO:** Complete the `parse_action` function to extract the tool name and argument from the LLM's response."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_response(text: str) -> dict:\n",
                "    \"\"\"\n",
                "    Parse the LLM's text response to extract either a Final Answer or an Action.\n",
                "    \n",
                "    Returns:\n",
                "        {\"type\": \"final_answer\", \"content\": \"...\"}\n",
                "        or\n",
                "        {\"type\": \"action\", \"tool\": \"search\", \"argument\": \"capital of france\"}\n",
                "        or\n",
                "        {\"type\": \"error\", \"content\": \"Could not parse response\"}\n",
                "    \"\"\"\n",
                "    # Check for Final Answer\n",
                "    final_match = re.search(r'Final Answer:\\s*(.+)', text, re.DOTALL)\n",
                "    if final_match:\n",
                "        return {\"type\": \"final_answer\", \"content\": final_match.group(1).strip()}\n",
                "    \n",
                "    # TODO: Parse the Action line to extract tool name and argument\n",
                "    # The format is: Action: tool_name(\"argument\")\n",
                "    # Hint: Use a regex like r'Action:\\s*(\\w+)\\(\"(.+?)\"\\)'\n",
                "    # Return: {\"type\": \"action\", \"tool\": tool_name, \"argument\": argument}\n",
                "    \n",
                "    # --- YOUR CODE HERE ---\n",
                "    pass\n",
                "    # --- END YOUR CODE ---\n",
                "    \n",
                "    return {\"type\": \"error\", \"content\": f\"Could not parse response: {text[:200]}\"}\n",
                "\n",
                "\n",
                "# Test the parser\n",
                "test1 = 'Thought: I need to find the capital.\\nAction: search(\"capital of france\")'\n",
                "test2 = 'Thought: I have enough info.\\nFinal Answer: Paris has 2.1 million people.'\n",
                "print(\"Test 1:\", parse_response(test1))\n",
                "print(\"Test 2:\", parse_response(test2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4: Build the Agent Loop\n",
                "\n",
                "Now the core — the `while` loop that drives the agent. Each iteration:\n",
                "1. Calls the LLM with the conversation history\n",
                "2. Parses the response for an Action or Final Answer\n",
                "3. If Action: executes the tool and appends the Observation\n",
                "4. If Final Answer: returns the result\n",
                "\n",
                "**TODO:** Complete the agent loop by:\n",
                "1. Calling the LLM with `completion()`\n",
                "2. Executing the tool when an action is parsed\n",
                "3. Appending the observation back to messages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_react_agent(query: str, max_steps: int = 5) -> dict:\n",
                "    \"\"\"\n",
                "    Run a text-based ReAct agent loop.\n",
                "    \n",
                "    Returns:\n",
                "        {\"answer\": str, \"steps\": list, \"total_steps\": int}\n",
                "    \"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": REACT_SYSTEM_PROMPT},\n",
                "        {\"role\": \"user\", \"content\": query},\n",
                "    ]\n",
                "    steps = []\n",
                "    \n",
                "    for step in range(max_steps):\n",
                "        print(f\"\\n{'='*50}\")\n",
                "        print(f\"Step {step + 1}\")\n",
                "        print(f\"{'='*50}\")\n",
                "        \n",
                "        # TODO 1: Call the LLM using litellm's completion()\n",
                "        # Hint: response = completion(model=MODEL, messages=messages, max_tokens=512)\n",
                "        # Then extract: assistant_text = response.choices[0].message.content\n",
                "        \n",
                "        # --- YOUR CODE HERE ---\n",
                "        assistant_text = \"\"  # Replace this\n",
                "        # --- END YOUR CODE ---\n",
                "        \n",
                "        print(f\"LLM Output:\\n{assistant_text}\")\n",
                "        \n",
                "        # Append assistant response to messages\n",
                "        messages.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
                "        \n",
                "        # Parse the response\n",
                "        parsed = parse_response(assistant_text)\n",
                "        steps.append({\"step\": step + 1, \"raw_output\": assistant_text, \"parsed\": parsed})\n",
                "        \n",
                "        if parsed[\"type\"] == \"final_answer\":\n",
                "            print(f\"\\nFinal Answer: {parsed['content']}\")\n",
                "            return {\"answer\": parsed[\"content\"], \"steps\": steps, \"total_steps\": step + 1}\n",
                "        \n",
                "        elif parsed[\"type\"] == \"action\":\n",
                "            tool_name = parsed[\"tool\"]\n",
                "            argument = parsed[\"argument\"]\n",
                "            \n",
                "            # TODO 2: Execute the tool and get the observation\n",
                "            # Hint: Look up the tool in TOOLS dict, call it with the argument\n",
                "            # Handle the case where the tool doesn't exist\n",
                "            \n",
                "            # --- YOUR CODE HERE ---\n",
                "            observation = \"\"  # Replace this\n",
                "            # --- END YOUR CODE ---\n",
                "            \n",
                "            print(f\"\\nObservation: {observation}\")\n",
                "            \n",
                "            # TODO 3: Append the observation back to messages\n",
                "            # The agent needs to see the tool result to continue reasoning\n",
                "            # Hint: Append as a user message with \"Observation: {observation}\"\n",
                "            \n",
                "            # --- YOUR CODE HERE ---\n",
                "            pass\n",
                "            # --- END YOUR CODE ---\n",
                "        \n",
                "        else:\n",
                "            print(f\"\\nParse error: {parsed['content']}\")\n",
                "            # Nudge the agent to follow the format\n",
                "            messages.append({\n",
                "                \"role\": \"user\",\n",
                "                \"content\": \"Please follow the exact format: Thought: ... Action: tool_name(\\\"argument\\\")\"\n",
                "            })\n",
                "    \n",
                "    return {\n",
                "        \"answer\": \"[Agent reached max steps without a final answer]\",\n",
                "        \"steps\": steps,\n",
                "        \"total_steps\": max_steps,\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5: Test Your Agent\n",
                "\n",
                "Try these queries — they require multi-step reasoning:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 1: Multi-step factual question\n",
                "result = run_react_agent(\"What is the population of the capital of France?\")\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"Answer: {result['answer']}\")\n",
                "print(f\"Total steps: {result['total_steps']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 2: Requires search + calculation\n",
                "result = run_react_agent(\"How tall is the Eiffel Tower in feet? What is that height divided by 3?\")\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"Answer: {result['answer']}\")\n",
                "print(f\"Total steps: {result['total_steps']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Reflection: The Pain Points\n",
                "\n",
                "After running the agent, think about these questions:\n",
                "\n",
                "1. **Did the parser always work?** Did the LLM deviate from the expected format?\n",
                "2. **How fragile is the regex?** What happens if the model writes `Action: search('query')` instead of `search(\"query\")`?\n",
                "3. **How would you handle multiple tool calls per step?** (Hint: you can't with text parsing — but native calling supports it)\n",
                "4. **How would you debug a failure?** You have the raw text, but no structured trace."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 2: Native Function Calling — The Production Approach\n",
                "\n",
                "Now let's compare with the **native** approach. Instead of parsing text, we use the LLM's built-in function calling API, which returns structured JSON.\n",
                "\n",
                "### The Key Differences\n",
                "\n",
                "| Aspect | Part 1 (Text) | Part 2 (Native) |\n",
                "|--------|---------------|------------------|\n",
                "| Tool format | Free text: `Action: search(\"...\")` | Structured JSON: `{\"name\": \"search\", ...}` |\n",
                "| Parsing | Regex (fragile) | `json.loads()` (guaranteed) |\n",
                "| Multiple tools | Not supported | Built-in support |\n",
                "| Error handling | Manual | API-level |\n",
                "| Debugging | Raw text | Structured tool_calls object |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define tools as OpenAI-compatible schemas\n",
                "TOOLS_SCHEMA = [\n",
                "    {\n",
                "        \"type\": \"function\",\n",
                "        \"function\": {\n",
                "            \"name\": \"search\",\n",
                "            \"description\": \"Search for information on a topic. Returns relevant text.\",\n",
                "            \"parameters\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"query\": {\n",
                "                        \"type\": \"string\",\n",
                "                        \"description\": \"The search query\"\n",
                "                    }\n",
                "                },\n",
                "                \"required\": [\"query\"]\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    {\n",
                "        \"type\": \"function\",\n",
                "        \"function\": {\n",
                "            \"name\": \"calculate\",\n",
                "            \"description\": \"Evaluate a mathematical expression. Returns the result.\",\n",
                "            \"parameters\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"expression\": {\n",
                "                        \"type\": \"string\",\n",
                "                        \"description\": \"The math expression to evaluate (e.g., '15 * 500 / 100')\"\n",
                "                    }\n",
                "                },\n",
                "                \"required\": [\"expression\"]\n",
                "            }\n",
                "        }\n",
                "    }\n",
                "]\n",
                "\n",
                "print(f\"Defined {len(TOOLS_SCHEMA)} tool schemas for native calling.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_native_agent(query: str, max_steps: int = 5) -> dict:\n",
                "    \"\"\"\n",
                "    Run an agent using native function calling.\n",
                "    No text parsing needed — the API returns structured tool calls.\n",
                "    \"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Use the provided tools to answer questions.\"},\n",
                "        {\"role\": \"user\", \"content\": query},\n",
                "    ]\n",
                "    steps = []\n",
                "    \n",
                "    for step in range(max_steps):\n",
                "        print(f\"\\n--- Step {step + 1} ---\")\n",
                "        \n",
                "        # Call LLM with tools parameter\n",
                "        response = completion(\n",
                "            model=MODEL,\n",
                "            messages=messages,\n",
                "            tools=TOOLS_SCHEMA,\n",
                "            tool_choice=\"auto\",\n",
                "            max_tokens=512,\n",
                "        )\n",
                "        \n",
                "        message = response.choices[0].message\n",
                "        assistant_content = message.content\n",
                "        tool_calls = message.tool_calls\n",
                "        \n",
                "        # Add assistant message to history\n",
                "        messages.append(message)\n",
                "        \n",
                "        step_info = {\"step\": step + 1, \"content\": assistant_content, \"tool_calls\": []}\n",
                "        \n",
                "        if assistant_content:\n",
                "            print(f\"Content: {assistant_content[:200]}\")\n",
                "        \n",
                "        # Handle tool calls — structured JSON, no parsing needed!\n",
                "        if tool_calls:\n",
                "            for tc in tool_calls:\n",
                "                func_name = tc.function.name\n",
                "                func_args = json.loads(tc.function.arguments)\n",
                "                \n",
                "                print(f\"Tool Call: {func_name}({func_args})\")\n",
                "                \n",
                "                # Execute tool\n",
                "                if func_name in TOOLS:\n",
                "                    result = TOOLS[func_name](**func_args)\n",
                "                else:\n",
                "                    result = f\"Error: Unknown tool '{func_name}'\"\n",
                "                \n",
                "                print(f\"Result: {result}\")\n",
                "                \n",
                "                step_info[\"tool_calls\"].append({\n",
                "                    \"tool\": func_name, \"args\": func_args, \"result\": result\n",
                "                })\n",
                "                \n",
                "                # Feed result back — structured format\n",
                "                messages.append({\n",
                "                    \"tool_call_id\": tc.id,\n",
                "                    \"role\": \"tool\",\n",
                "                    \"name\": func_name,\n",
                "                    \"content\": result,\n",
                "                })\n",
                "        \n",
                "        steps.append(step_info)\n",
                "        \n",
                "        # If no tool calls and we have content, the agent is done\n",
                "        if not tool_calls and assistant_content:\n",
                "            return {\"answer\": assistant_content, \"steps\": steps, \"total_steps\": step + 1}\n",
                "    \n",
                "    return {\n",
                "        \"answer\": \"[Max steps reached]\",\n",
                "        \"steps\": steps,\n",
                "        \"total_steps\": max_steps,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the native agent with the same query\n",
                "result = run_native_agent(\"What is the population of the capital of France?\")\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"Answer: {result['answer']}\")\n",
                "print(f\"Total steps: {result['total_steps']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 3: Compare and Reflect\n",
                "\n",
                "### Side-by-Side Comparison\n",
                "\n",
                "Run both agents on the same query and compare:\n",
                "\n",
                "| Metric | Text-Based | Native |\n",
                "|--------|-----------|--------|\n",
                "| Steps taken | ? | ? |\n",
                "| Parse errors | ? | 0 (guaranteed) |\n",
                "| Code complexity | High (regex) | Low (structured) |\n",
                "| Debugging ease | Hard | Easy |\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "1. **Text-based parsing is fragile** — the model may deviate from the format in subtle ways\n",
                "2. **Native calling is robust** — structured JSON from the API, no regex needed\n",
                "3. **Text-based teaches the mechanics** — you understand what native calling does under the hood\n",
                "4. **Both are the same loop** — `while` + state + reasoning. Only the interface differs.\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "Open the project's `src/agent/react_agent.py` and compare with your native agent above. Note how it:\n",
                "- Uses a `ToolRegistry` for dynamic tool management\n",
                "- Implements proper error handling with try/except\n",
                "- Logs each step for debugging (preview of Session 3's tracing)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}